
% MS: I found a couple of typos. Is someone resolving those otherwise I can do it.
\section{Introduction}

Data Quality and Data Integration are two major problems which are becoming critical for health care providers everywhere. Research data is held on different systems, in different locations and the data itself is heterogeneous, collected without a common syntax or semantics. Data quality within the enterprise is dependent on successfully managing heterogeneous data sources, and there are variety of approaches to solve the problems associated with data integration.   The successful application of metadata registries together with model driven engineering has been demonstrated to have a significant impact on these problems within two major healthcare projects within the UK's National Health Service (NHS).

The UK's National Institute for Health Research (NIHR \cite{NIHR}) has sponsored the Health Informatics Collaberative (NHIC) which is backing a cross-trust programme involving 5 key NHS hospital trusts in the UK in order to set up a flexible and responsive governance framework, whereby research outcomes can rapidly be exploited by the NHS community. The work is currently limited to 5 clinical areas, but is expected in time to be extended. One of the aims of the programme is to develop tools and services for research, so that researchers can clinicians can have access to a wider cross Biomedical Research Centre (BRC) dataset. The programme has been working on developing a federated metadata registry, based on the ISO standard for metadata registries ISO11179\cite{ISO11179}, for use as a basis for enabling interoperability primarily for research data from clinical trials but also with a view to integrating this capability with Electronic Patient Records (EPR) data within the trusts.

Genomics England (GEL \cite{GEL}) is a research company wholly owned by the UK's NHS, which has been created ......

\subsection{Background}

Interoperability is major problem in electronic information systems in 2 orthogonal respects, firstly that domain concepts and terms in multiple systems are used to mean slightly different things, and secondly that the same concept meaning in different systems very often are given a different representation, so that speed may be represented by an Integer value in one systems and by a Double in another system.

The idea of a data dictionary has been around since databases first become common instruments for storing and manipulating data. A data dictionary is  the idea of a metadata registry stems from a similar notion.
Metadata Registries are needed in organizations to ensure data consistency. Metadata Registries are capable of analysing, administering and classifying metadata and very often in practise they also function as repositories for metadata, storing the schema and blueprints for data types and structures. The ideas and concepts that are stored in data systems form the basis of executable software systems, however many of the details are peculiar to particular disciplines.  

In the past Data Dictionaries were used to store details of database record structure or application data structure on a local per application basis, a metadata registry provides a similar capability but on a system or organisation-wide basis. It also provides features that are commonly included in a \emph{Thesaurus}, a \emph{Taxonomy}, and an \emph{Ontology} . These features include the ability to classify terms in relation to one another, record relationships such as synonyms, and classify hierarchical relationships. Ontologies have proved effective in matching what we define as the first problem, that is how domain concepts can be matched, however they are quite unwieldy to use when tackling the second problem of how to match and manage different representations.

Metadata Registries are normally found in Data Warehouses and Enterprise data mining systems, where vast quantities of data need to be administered and managed. It is likely that metadata registries will become more common as it becomes more and more necessary to deal with the recent internet-driven data explosion, especially as much of this data is unstructured, and can only be processed by relatively inefficient techniques.

Metadata Registries contain the ability to examine both how a data element is represented as well as to record it means, and it is this relationship that is embodied in the International Standard 11179, which we will examine in the next section. There are other standards which are concerned with metadata registries namely ISO15000 (part 3 and 4)  which relates to ebXML, however they are more concerned with storing and accessing metadata rather than classifying it and relating the semantic and representational aspects of that metadata.

\subsection{ISO11179}
ISO11179 is the international standard relating to metadata and in particular metadata registries, and although there are a few other related standards which have informed the specification of the toolkit we describe ISO11179 provides the most exhaustive description of a metadata registry. It is therefore a key reference in this specification.




\begin{figure}[here]
	\includegraphics[width=0.48\textwidth,natwidth=610,natheight=642]{Basic11179}
	\caption{Core model for ISO11179 Metadata Registry} 
	\label{fig:basicMDR}
\end{figure}

The core ideas from the ISO11179 standard can be extracted to give us the notion of a \emph{data element concept}, \emph{a data element}, \emph{a value domain}, and a \emph{conceptual domain}. The standard currently confines itself to the detailed level of concepts and data elements and has no notion of collections of data elements or data element concepts, but instead attaches two attributes: an \emph{object class} and a \emph{property} to each DEC, these attributes allow DEC's to be aggregated or classified. This core model of the ISO11179 is illustrated in figure \ref{fig:basicMDR}.


\subsection{Related Work}
% MS: If this section is to be supported by two pages of references,
% it needs its own space. This can be merged with section 3.

Data warehousing provides support to model meta data towards reporting and analysis in the context of enterprise data systems. In data warehousing models of meta data are used extract data from separate business systems into a single data warehouse, for decision support. Data warehouse models can be arranged in normalised form, following a relational approach, or dimensional form as quantifiable \emph{facts} and \emph{dimensions} that denote the context of facts. Data warehousing relies on fixed data models and structures, which is in contrast to the more general approach taken in ISO 11179, where models are expected to change over time. 

The Common Warehouse Metamodel (CWM)~\cite{poole03} from the Object Management Group is a UML based standard to enable data warehousing in practice. However, as with data warehousing, CWM is focused on write-once models, and for working with rigidly structured data. The models and data warehouse structure in CWM are not intended to change after creation. The standard consists of 22 parts and the core meta model shares defines an equivalent to the \emph{concept} and \emph{value} elements of the ISO11179 meta model.

%Seyyed: Iâ€™ll add some more here on meta model repositories and the MDE papers on metamodelling


%%%%  ontological representations of ISO11179 %%%%%%%%

Several efforts have addressed the representation of ISO11179 as
ontological models for enabling data integration across metadata
registries (MDRs). In \cite{Sinaci2013784} the authors describe a
federated semantic metadata registry framework where CDE (Common Data
Elements) are exposed as LOD resources. CDEs are described in RDF, can
be queried and interlinked with CDEs in other registries using
SKOS. An ISO1179 ontology has been defined as part of the framework
and the Semantic MDR has been implemented using the Jena framework. In
\cite{pmid25405066} the authors present the Clinical Data Element
Ontology (CDEO) for unified indexing and retrieval of elements across
MDRs. Concepts in CDEO have been organised and represented using
SKOS. In \cite{pmid22211181} the authors present case studies for
representing HL7 Detailed Clinical Models (DCMs) and the ISO11179
model in OWL. A combination of UML diagrams and Excel spreadsheets
were used to extract the metamodels for 14 HL7 DCM constructs. A
critical limitation of this approach is that the transformation from
metamodels to their ontological representation in OWL is based on a
manual encoding.

%%%% Ontology repositories %%%%%%%%%



\subsection{Objectives}
This paper is an experience paper showing the results obtained from applying Model Driven Engineering principles to data interoperability problems in two instances in the medical domain. In both cases the aims of the clinicians were similar, namely to integrate existing clinical trials data and to ensure that future artefacts, such as the forms used to capture datasets resulted in high data quality. 

To measure data quality we looked at how the data forms used in capturing information conformed to the standards relating to the datasets used, in particular was the terminology uniform, did captured data elements mean the same thing, and did equivalent data elements capture the same values across different systems.


The paper is split into 5 sections, this section introduces the problem and gives an overview of the work, the next section looks at the core language or model used, section 3 deals with the implem   entation details, section 4 details the experience gained, in essence the results achieved and section 5 concludes.
