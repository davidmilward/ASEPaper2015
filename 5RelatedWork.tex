
\section{Related Work}

A range of tools are available for clinical Electronic Data Capture (EDC) including Catalyst Web Tools~\cite{catalyst}, OpenClinica~\cite{oc}, REDCap~\cite{harr09}, LabKey~\cite{labk} and Caisis~\cite{cais}. A two-year case-study comparing EDC tools is available in~\cite{fran11}, a further study comparing Clinical Trials Management Systems is found in~\cite{lero11}. In the current paper, OpenClinica case report forms (CRFs) forms are generated using the Model Catalogue tool, however, CRFs for any EDC tool may be generated. State-of-the-art in EDC is the research electronic data capture (REDCap)~\cite{harr09} web-based application. The REDCap tool supports meta data capture for research studies providing an online interface for data entry, audit trails, export to common statistical packages and data import from external sources. Like the Model Catalogue, the REDCap system focuses on the clinical metadata. However, REDCap and similar tools differs from the Model Catalogue in several important aspects. Firstly, EDC tools tend to be insular and centralised systems, any data must be imported into and stored within the CEDC database, which acts as a silo. The Model Catalogue aims to provide a platform to support existing data stores and systems within the clinical environment. 

There is also a wide-gap in the level of expertise required to operate the tools. The meta-data management (creation, revision, sharing) in CEDC is considered a specialist task~\cite{harr09,fran11}, requiring experts to initialise a the meta-data per-study. In the Model Catalogue, clinical users have the ability to adapt and modify metadata as needed, and treat models as the central artefact. Effectively, the Model Catalogue follows the same metadata workflow as REDCap, but without the need for modelling experts to develop, adapt or to share the meta data models. REDCap, unlike the Model Catalogue, is not open source so users cannot freely modify the functionality of the system. The Model Catalogue, can be modified to add features and support to maximise the utility of the models. Because the Model Catalogue works at the meta-data level, users can share similar models between organisations and derive new software artefacts from user created metadata models.

Several examples of Model Driven Engineering for e-Heath software are present in the literature~\cite{dav14,ragh08,blob07,kham08,schl15}. The typical pattern followed in these methods is one formalised in~\cite{pay12}, which advocates a multi-phase approach, where data modelling is a separate phase from stakeholder engagement and data integration. This approach is taken in~\cite{kham08}, where an Eclipse-based tool is used to develop DSLs to model and generate tools for mobile heath tracking applications. The advantage of the approach is the ability for clinicians to modify the model of the study, using a DSL, and automated creation of applications from the model. A similar approach is taken in the \emph{True Colours} system~\cite{dav14}, using the Booster model driven toolkit to derive a patient self-monitoring application for mental health. The Booster approach shows how data tends to be managed better by a model driven process, which leads to higher quality, reusable data. In~\cite{schl15}, the authors present experiences on the use of Model Driven Engineering to implement an application for path-based stroke care; amongst the experiences included using existing ontological models, where possible and using an adoptive modelling toolkit. Unlike these systems, in the model catalogue, a meta-data oriented approach is taken so the applications created using models can be made interoperable with existing data, standards and systems. Rather than simply using MDE to develop stand-alone systems, MDE processes are used in the management of clinical trials meta-data from which software is derived. 

In the Model Driven Health Tools (MDHT)~\cite{MDHT} project, the HL7 Clinical Document Architecture (CDA) standard~\cite{doli06} for managing patient records is implemented using Eclipse UML tools~\cite{EUML}. The benefits of applying model driven engineering are clear, modelling tools are used to model the CDA standards and interoperable implementations of the standard are automatically derived from the models. In principle, this is similar to the approach in the model catalogue, where the CDA meta-data can be represented and implementations derived. However, MDHT supports only the CDA standard, whereas the model catalogue can interoperate with any meta data standard. The CDA standards are large and complex, in~\cite{sco12}, a model driven approach is advocated to simplify the HL7 CDA. This is supported by three case studies: the NHS England ‘Interoperability Toolkit’ (ITK); simplification of US CDA documents and the Common Assessment Framework (CAF) project for health and care providers in England. The paper outlines the benefits of simplifying the CDA standard for practical applications. The model catalogue supports similar simplifications, where large and complex meta data schemes are simplified by mapping only relevant meta data in the generated artefacts.


%could do with some stuff about caBIG caCORE CancerGrid ADAM!


%%%%  ontological representations of ISO11179 %%%%%%%%

Several efforts have addressed the representation of ISO11179 as
ontological models for enabling data integration across metadata
registries (MDRs). In \cite{Sinaci2013784} the authors describe a
federated semantic metadata registry framework where CDE (Common Data
Elements) are exposed as LOD (Linked Open Data) resources. CDEs are
described in RDF, can be queried and interlinked with CDEs in other
registries using SKOS. An ISO1179 ontology has been defined as part of
the framework and the Semantic MDR has been implemented using the Jena
framework. In \cite{pmid25405066} the authors present the Clinical
Data Element Ontology (CDEO) for unified indexing and retrieval of
elements across MDRs. Concepts in CDEO have been organised and
represented using SKOS. In \cite{pmid22211181} the authors present
case studies for representing HL7 Detailed Clinical Models (DCMs) and
the ISO11179 model in OWL. A combination of UML diagrams and Excel
spreadsheets were used to extract the metamodels for 14 HL7 DCM
constructs. A critical limitation of this approach is that the
transformation from metamodels to their ontological representation in
OWL \footnote{} is based on a manual encoding.

%%%% Ontology repositories %%%%%%%%%

Ontology repositories can be considered closely analogous to model
catalogues they provide the infrastructure for storing, interlinking,
querying, versioning and visualising ontologies. Relationships
capturing the alignments and mappings between ontologies are also
captured allowing easy navigability.

Linked Open vocabularies\cite{LOV} provides a service for discovering
vocabularies and ontologies published following the principles of
linked data. Besides the above features, it provides documentation
about ontologies automatically harvested from their structure and
identifies dependencies.

Apache Stanbol\cite{Stanbol} provides a set of reusable components for Semantic
content management.  The Apache Stanbol Ontology Manager provides a
controlled environment for managing ontologies and ontology
networks. Main components of the manager include (a) Ontonet, a Java
API for the construction and management of ontology networks from the
ontology knowledge base. (b) Registry, an RDF resource that provides
descriptions of ontology libraries in the knowledge base. The registry
also provides a management API for administrators to pre-configure
sets of ontologies loaded in the ontology libraries.

KAON2\cite{Kaon2} provides an API infrastructure for managing OWL-DL,
SWRL and F-Logic ontologies. Access to the ontologies is provided via
a single stand alone server. OWL DL Inferencing and SPARQL based
querying are supported.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Data warehousing~\cite{kim02} provides a framework for reporting and analysis tasks across disparate enterprise data systems, for decision support. In data warehousing meta data is modelled to extract information from business systems into a centralised data warehouse. The warehouse is used to create reports and analyse business performance. Data warehouse models can be arranged in normalised form, following the relational approach~\cite{inm92}, or `dimensional’ form~\cite{kim02} as quantifiable \emph{facts} and \emph{dimensions} which denote the context of facts. Data warehousing relies on fixed data models and structures, which is in contrast to the more general approach taken in ISO11179, where models are expected to change over time. 

The Common Warehouse Metamodel (CWM)~\cite{poole03} from the Object Management Group is a UML based framework to enable data warehousing in practice. However, as with data warehousing, CWM is focused on write-once models, and for working with rigidly structured data. The models and data warehouse structure in CWM are not intended to change after creation and data is copied into the data warehouse from separate systems. The standard consists of 22 parts and the core meta model has overlap with the the \emph{concept} and \emph{value} elements of the ISO11179 meta model.

